Import('env')
import scons_tools.examples

env= env.IMPSystem(version="SVN",
                   authors=["Keren Lasker"],
                   brief="Compute a structure for the humap RNAPII complex.",
                   overview="""
\\section input Input files
The input files are
 - \\c subunits.txt which contains a list of the subunits and the path to the pdb file for the structure of each
 - the mentioned pdb files, located in the \\c data directory
 - the \\c .mrc file for the assembly, also located in the \\c data directory

\\section generate_params Generating structures

First we need to generate the paramters files for running multifit.
\\command{$IMP/tools/imppy.sh python $IMP/modules/multifit2/bin/generate_assembly_input.py -i rnapii.asmb.input -- rnapii subunits.txt 10 data/emd_1283.mrc 20 2.5 0.2 60 60 60}

We the run multifit to create all the surfaces {what does this mean?}
\\command{$IMP/tools/imppy.sh python $IMP/modules/multifit2/bin/create_all_surfaces.py rnapii.asmb.data}

We then generate the anchor graph
\\command{$IMP/tools/imppy.sh python $IMP/modules/multifit2/bin/generate_assembly_anchor_graph.py rnapii.asmb.data rnapii.asmb.anchors}

This generates the following files:
 - \\c rnapii.asmb.anchors.pdb The graph in pdb format
 - \\c rnapii.asmb.anchors.txt The graph in txt format
 - \\c rnapii.asmb.anchors.cmm The graph in cmm format

We then need to fit the subunits. We could do all at once in parallel by running
\\command{$IMP/tools/imppy.sh python $IMP/modules/multifit2/bin/run_fitting_fft.py -p rnapii.multifit.param  rnapii.asmb.data -c 6}
where \\c -c specifies the number of processes to use. See $IMP/modules/multifit2/example for more such examples.

However, since the first two subunits are much larger than the rest, we first fit fit and assemble the first two subunits and then the rest:

We start by creating a parameter file just for the first two subunits:
\\command{$IMP/tools/imppy.sh python $IMP/modules/multifit2/bin/generate_assembly_input.py -i RPB1.RPB2.asmb.input -- rnapii RPB1_RPB2_subunits.txt 10 data/emd_1283.mrc 20 2.5 0.2 60 60 60}

and then fit the two subunits

\\command{$IMP/tools/imppy.sh python $IMP/modules/multifit2/bin/run_fitting_fft.py -p rnapii.multifit.param  RPB1.RPB2.asmb.data -c 2 -a 15}

generate indexes
We now create fit indexes for the assembly {What does this mean?}
\\command{$IMP/tools/imppy.sh python $IMP/modules/multifit2/bin/generate_indexes_from_fitting_solutions.py RPB1_RPB2 RPB1_RPB2.asmb.input 10}

Assemble only the first two subunits.

create a proteomics file
\\command{$IMP/tools/imppy.sh python $IMP/modules/multifit2/bin/create_auto_proteomics_file.py 1z5s.asmb.input 1z5s.asmb.anchors.txt  1z5s.proteomics.input}

\\c 1z5s.asmb.anchors.txt was generated above. This will generate \\c 1z5s.proteomics.input.

We then assemble the fitting solutions:
\\command{$IMP/tools/imppy.sh python $IMP/modules/multifit2/bin/align_proteomics_em_atomic_plan.py -m 30 1z5s.asmb.input 1z5s.proteomics.input 1z5s.indexes.mapping.input 1z5s.alignment.param 1z5s.docking.param combinations.output scores.output}

Now segment RPB1, RPB2 from the density and fit the rest of the subunits

Now assemble all of the subunits together
                   """,
                   license=env.IMPStandardLicense(),
                   # jeremy, update the publication(s)
                   publications=[env.IMPPublication(authors=["Keren Lasker", "Daniel Russel", "Jeremy Phillips", "Haim Wolfson", "Andrej Sali"],
                                                    title="Determining architectures of macromolecular assemblies by aligning interaction networks to electon microscopy density maps",
                                                    journal="submitted",
                                                    year=2011)],
                   required_modules=['core', 'atom', 'rmf', 'multifit'],
                   last_imp_version="""None""",
                   # this is true if the scripts can be run incompletely as test cases
                   # eg if it works to do "sample_0.py 1 1000" and then "analyze_0.py"
                   # without doing all of the sampling required. This can be implementedf
                   # either by providing intermediate data or by only analyzing the data
                   # that happens to be there
                   testable=False, parallelizable=False)
#if env:
#    files= ["setup",
#            "sample_0",
#            "analyze_0"]
#    scons_tools.examples.add_python_example(env, "setup.py",
#                                            "General setup code common to sampling and analysis.")
#    scons_tools.examples.add_python_example(env, "sample_0.py",
#                                            "Sampling using MCCG and random starting points.")
#    scons_tools.examples.add_python_example(env, "analyze_0.py",
#                                            "Cluster into 10 solutions.")
#    scons_tools.examples.add_page(env, "Example system code",
#                                  [x+".py" for x in files])
